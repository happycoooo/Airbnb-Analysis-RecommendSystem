{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note scipy==1.7.3 has the function 'triu', which is needed in Word2Vec\n",
    "# pip uninstall scipy -y\n",
    "# !pip install scipy==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LinAlgError', 'LinAlgWarning', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_decomp_cossin', '_decomp_ldl', '_decomp_polar', '_decomp_qz', '_decomp_update', '_expm_frechet', '_fblas', '_flapack', '_flinalg', '_interpolative', '_interpolative_backend', '_matfuncs_sqrtm', '_matfuncs_sqrtm_triu', '_procrustes', '_sketches', '_solve_toeplitz', '_solvers', 'basic', 'blas', 'block_diag', 'cdf2rdf', 'cho_factor', 'cho_solve', 'cho_solve_banded', 'cholesky', 'cholesky_banded', 'circulant', 'clarkson_woodruff_transform', 'companion', 'convolution_matrix', 'coshm', 'cosm', 'cossin', 'cython_blas', 'cython_lapack', 'decomp', 'decomp_cholesky', 'decomp_lu', 'decomp_qr', 'decomp_schur', 'decomp_svd', 'det', 'dft', 'diagsvd', 'eig', 'eig_banded', 'eigh', 'eigh_tridiagonal', 'eigvals', 'eigvals_banded', 'eigvalsh', 'eigvalsh_tridiagonal', 'expm', 'expm_cond', 'expm_frechet', 'fiedler', 'fiedler_companion', 'find_best_blas_type', 'flinalg', 'fractional_matrix_power', 'funm', 'get_blas_funcs', 'get_lapack_funcs', 'hadamard', 'hankel', 'helmert', 'hessenberg', 'hilbert', 'interpolative', 'inv', 'invhilbert', 'invpascal', 'khatri_rao', 'kron', 'lapack', 'ldl', 'leslie', 'logm', 'lstsq', 'lu', 'lu_factor', 'lu_solve', 'matfuncs', 'matmul_toeplitz', 'matrix_balance', 'misc', 'norm', 'null_space', 'ordqz', 'orth', 'orthogonal_procrustes', 'pascal', 'pinv', 'pinv2', 'pinvh', 'polar', 'qr', 'qr_delete', 'qr_insert', 'qr_multiply', 'qr_update', 'qz', 'rq', 'rsf2csf', 'schur', 'signm', 'sinhm', 'sinm', 'solve', 'solve_banded', 'solve_circulant', 'solve_continuous_are', 'solve_continuous_lyapunov', 'solve_discrete_are', 'solve_discrete_lyapunov', 'solve_lyapunov', 'solve_sylvester', 'solve_toeplitz', 'solve_triangular', 'solveh_banded', 'special_matrices', 'sqrtm', 'subspace_angles', 'svd', 'svdvals', 'tanhm', 'tanm', 'test', 'toeplitz', 'tri', 'tril', 'triu']\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "print(dir(scipy.linalg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('./data/listings.csv')\n",
    "listings.isnull().sum()\n",
    "selection = ['id','name','description','neighborhood_overview','host_is_superhost', 'host_response_time',\n",
    "             'host_response_rate','host_acceptance_rate','host_total_listings_count',  \n",
    "             'neighbourhood','latitude','longitude','property_type','room_type','accommodates','bathrooms',\n",
    "             'bathrooms_text','bedrooms','beds','amenities','price','number_of_reviews','review_scores_rating', \n",
    "             'review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
    "             'review_scores_communication', 'review_scores_location','review_scores_value',\n",
    "             'instant_bookable']  \n",
    "selected_listings = listings[selection]\n",
    "selected_listings.loc[:,'description'] = selected_listings['description'].astype(str).str.replace('<br />', '').apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "# selected_listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time, room_type, bathrooms_text\n",
    "category_columns = ['host_response_time', 'room_type', 'bathrooms_text']\n",
    "# selected_listings = pd.get_dummies(selected_listings, columns=category_columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in category_columns:\n",
    "    selected_listings.loc[:,column] = label_encoder.fit_transform(selected_listings.loc[:,column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_93136\\1993394598.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_listings.dropna(subset=numeric_features, inplace=True)\n",
      "C:\\Windows\\Temp\\ipykernel_93136\\1993394598.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.4062414  -0.41713777 -0.01397218 ... -0.42803414  0.06230239\n",
      " -0.42803414]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  selected_listings.loc[:,numeric_features] = scaler.fit_transform(selected_listings.loc[:,numeric_features])\n",
      "C:\\Windows\\Temp\\ipykernel_93136\\1993394598.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.81333409 -0.03571123 -1.20214552 ... -0.03571123 -0.81333409\n",
      " -0.81333409]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  selected_listings.loc[:,numeric_features] = scaler.fit_transform(selected_listings.loc[:,numeric_features])\n",
      "C:\\Windows\\Temp\\ipykernel_93136\\1993394598.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.55682354 -0.55682354 -0.11175113 ...  0.63482196 -0.55682354\n",
      "  0.83582241]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  selected_listings.loc[:,numeric_features] = scaler.fit_transform(selected_listings.loc[:,numeric_features])\n",
      "C:\\Windows\\Temp\\ipykernel_93136\\1993394598.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_listings.dropna(subset=rate_columns, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# deal with x% (transform string type to float)\n",
    "def percentage_to_float(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    else:\n",
    "        return float(value) / 100\n",
    "\n",
    "# Convert percentage strings to float\n",
    "selected_listings.loc[:,'host_response_rate'] = selected_listings.loc[:,'host_response_rate'].str.replace('%', '')\n",
    "selected_listings.loc[:,'host_acceptance_rate'] = selected_listings.loc[:,'host_acceptance_rate'].str.replace('%', '')\n",
    "selected_listings.loc[:,'price'] = selected_listings.loc[:,'price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "numeric_features = ['host_response_rate', 'host_acceptance_rate', 'host_total_listings_count', 'price',\n",
    "                    'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds','number_of_reviews']\n",
    "selected_listings.dropna(subset=numeric_features, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "selected_listings.loc[:,numeric_features] = scaler.fit_transform(selected_listings.loc[:,numeric_features])\n",
    "\n",
    "rate_columns = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', \n",
    "                'review_scores_checkin', 'review_scores_communication','review_scores_location', \n",
    "                'review_scores_value']\n",
    "selected_listings.dropna(subset=rate_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_features = ['instant_bookable','host_is_superhost']\n",
    "selected_listings.loc[:, 'instant_bookable'] = selected_listings['instant_bookable'].apply(lambda x: 1 if x == 't' else 0)\n",
    "selected_listings.loc[:,'host_is_superhost'] = selected_listings['host_is_superhost'].apply(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train Word2Vec model for text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text features: name, description, neighborhood_overview, property_type, neighbourhood, amenities\n",
    "corpus = selected_listings['name'].fillna('')+ selected_listings['description'].fillna('') + selected_listings['neighborhood_overview'].fillna('') + ' ' + selected_listings['property_type'].fillna('') + ' ' + selected_listings['neighbourhood'].fillna('') + ' ' + selected_listings['amenities'].fillna('')\n",
    "tokenized_corpus = corpus.apply(lambda x: word_tokenize(x.lower()))\n",
    "# train word2vec model\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10313/10313 [01:30<00:00, 114.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0) if doc else np.zeros(model.vector_size)\n",
    "\n",
    "doc_vectors = []\n",
    "\n",
    "# Manually iterate over the tokenized corpus with a progress bar\n",
    "for doc in tqdm(tokenized_corpus, total=len(tokenized_corpus)):\n",
    "    vector = document_vector(doc)\n",
    "    doc_vectors.append(vector)\n",
    "\n",
    "# Convert list to DataFrame or Series, depending on your requirement\n",
    "doc_vectors = pd.Series(doc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Items Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = selected_listings[category_columns+numeric_features+rate_columns+boolean_features]\n",
    "combined_features = np.hstack([features, doc_vectors.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10313, 123)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499522, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('./data/reviews-Sydney.csv')\n",
    "reviews.isnull().sum()\n",
    "reviews.dropna(inplace=True)\n",
    "reviews['comments'] = reviews['comments'].str.replace('<br/>', '').apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "reviews_column = ['id','reviewer_id','comments']\n",
    "reviews = reviews[reviews_column]\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>Cat is a such a caring and pleasant host, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>You cannot beat the location of this place. An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>795</td>\n",
       "      <td>We really enjoyed Linda’s place. We felt at ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1008</td>\n",
       "      <td>StudioKB was just right for what I needed - ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1187</td>\n",
       "      <td>The location and view are unparalleled, checki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id                                           comments\n",
       "0           19  Cat is a such a caring and pleasant host, and ...\n",
       "1           46  You cannot beat the location of this place. An...\n",
       "2          795  We really enjoyed Linda’s place. We felt at ho...\n",
       "3         1008  StudioKB was just right for what I needed - ve...\n",
       "4         1187  The location and view are unparalleled, checki..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_grouped = reviews.groupby('reviewer_id')['comments'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "reviews_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fyr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fyr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return words\n",
    "\n",
    "reviews_grouped['processed_comments'] = reviews_grouped['comments'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=reviews_grouped['processed_comments'], vector_size=100, window=5, min_count=2, workers=4)\n",
    "model.save(\"word2vec_reviewer_comments.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "    return feature_vector\n",
    "\n",
    "vocabulary = set(model.wv.index_to_key)\n",
    "reviews_grouped['feature_vector'] = reviews_grouped['processed_comments'].apply(\n",
    "    lambda x: average_word_vectors(x, model, vocabulary, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.array(reviews_grouped['feature_vector'].tolist())\n",
    "num_users = user_features.shape[0]\n",
    "additional_features = np.zeros((num_users, 23))\n",
    "\n",
    "# combine with function hstack\n",
    "user_features = np.hstack([user_features, additional_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf462f45441465b89d85466b6ae7c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=0, description='Please input a user ID:', style=DescriptionStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "id_input = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Please input a user ID:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(description=\"Search\", button_style='success') \n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        user_id = id_input.value\n",
    "        if 0 <= user_id <= 412495:\n",
    "            try:\n",
    "                single_user_feature = user_features[user_id].reshape(1, -1)\n",
    "                similarities = cosine_similarity(single_user_feature, combined_features)[0]\n",
    "                indexed_similarities = list(zip(selected_listings['id'], similarities))\n",
    "                sorted_listings = sorted(indexed_similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                top_n = 5\n",
    "                top_recommendations = sorted_listings[:top_n]\n",
    "                recommended_ids = [item[0] for item in top_recommendations]\n",
    "                recommend_listings = listings[listings['id'].isin(recommended_ids)]\n",
    "                \n",
    "                data = {'Room ID': recommended_ids,\n",
    "                        'Room Link': [f'<a href=\"{link}\">{link}</a>' for link in recommend_listings['listing_url']]}\n",
    "                df = pd.DataFrame(data)\n",
    "                \n",
    "                display(HTML(df.to_html(escape=False)))\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {e}\")\n",
    "        else:\n",
    "            print(\"Please input a valid user ID (from 0 to 412495).\")\n",
    "\n",
    "submit_button.on_click(on_button_clicked)\n",
    "\n",
    "form = widgets.VBox([widgets.HBox([id_input, submit_button]), output])\n",
    "display(form)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
